{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello and Greetings!\n",
    "This code contains enviroment, algorithm and policy extraction for open AI gym frozen lake environment!\n",
    "You can get more example and info from open ai gym library at https://www.gymlibrary.dev/\n",
    "I have used the frozen lake environment which you can have a look at https://www.gymlibrary.dev/environments/toy_text/frozen_lake/\n",
    "There are also two algorithms to solve this problem: 1- value iteration method, 2- Q-learning method\n",
    "They both contain training using gym envinroment in addition to test and policy extraction!\n",
    "\n",
    "Best wishes \n",
    "Amir Hossein Nourian \n",
    "ahn.paf@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making gym environment (default environment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, {'prob': 1})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frozen-lake-ex1.py\n",
    "import gym # loading the Gym library\n",
    " \n",
    "env = gym.make(\"FrozenLake8x8-v1\",render_mode=\"human\",is_slippery=False)\n",
    "#env = gym.make(\"FrozenLake8x8-v1\",is_slippery=False)\n",
    "env.reset()                    \n",
    "#env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making gym environment (4x4 environment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "m_44 =[\n",
    "    \"SFFF\",\n",
    "    \"HHFH\",\n",
    "    \"FHFF\",\n",
    "    \"FFFG\",\n",
    "] \n",
    "\n",
    "env = gym.make(\"FrozenLake-v1\",desc=m_44,map_name=\"4x4\",is_slippery=False)\n",
    "\n",
    "# env1\n",
    "\n",
    "import gym\n",
    "m_44_1 =[\n",
    "    \"SFFF\",\n",
    "    \"FFFF\",\n",
    "    \"FFFF\",\n",
    "    \"FFFG\",\n",
    "] \n",
    "\n",
    "env1 = gym.make(\"FrozenLake-v1\",desc=m_44_1,map_name=\"4x4\",is_slippery=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "#1\n",
    "\n",
    "m_66_1 =[\n",
    "    \"SFFFFF\",\n",
    "    \"FFFFFF\",\n",
    "    \"FFFFFF\",\n",
    "    \"FFFFFF\",\n",
    "    \"FFFFFF\",\n",
    "    \"FFFFFG\",\n",
    "] \n",
    "\n",
    "env1 = gym.make(\"FrozenLake-v1\",desc=m_66_1,map_name=\"6x6\",is_slippery=False)\n",
    "\n",
    "#2\n",
    "\n",
    "m_66_2 =[\n",
    "    \"SFFFFF\",\n",
    "    \"HHHHHF\",\n",
    "    \"FFFFFF\",\n",
    "    \"FHHHHH\",\n",
    "    \"FFFFFF\",\n",
    "    \"HHHHHG\",\n",
    "] \n",
    "\n",
    "env2 = gym.make(\"FrozenLake-v1\",desc=m_66_2,map_name=\"6x6\",is_slippery=False)\n",
    "\n",
    "#3\n",
    "\n",
    "m_66_3 =[\n",
    "    \"SFFFFF\",\n",
    "    \"FHFHFH\",\n",
    "    \"FFFFFF\",\n",
    "    \"FHFHFH\",\n",
    "    \"FFFFFF\",\n",
    "    \"FHFHFG\",\n",
    "] \n",
    "\n",
    "env3 = gym.make(\"FrozenLake-v1\",desc=m_66_3,map_name=\"6x6\",is_slippery=False)\n",
    "\n",
    "\n",
    "#4\n",
    "\n",
    "m_66_4 =[\n",
    "    \"SFFFFF\",\n",
    "    \"FHFHFH\",\n",
    "    \"FFFFFF\",\n",
    "    \"HHHHHF\",\n",
    "    \"FFFFFF\",\n",
    "    \"FHFHFG\",\n",
    "] \n",
    "\n",
    "env4 = gym.make(\"FrozenLake-v1\",desc=m_66_4,map_name=\"6x6\",is_slippery=False)\n",
    "\n",
    "#5 \n",
    "\n",
    "m_66_5 =[\n",
    "    \"SFFFFF\",\n",
    "    \"FHFHFH\",\n",
    "    \"FFFFFF\",\n",
    "    \"FHHHHF\",\n",
    "    \"FFFFFF\",\n",
    "    \"FHFHFG\",\n",
    "] \n",
    "\n",
    "env5 = gym.make(\"FrozenLake-v1\",desc=m_66_5,map_name=\"6x6\",is_slippery=False)\n",
    "\n",
    "#6\n",
    "\n",
    "m_66_6 =[\n",
    "    \"SFFFFF\",\n",
    "    \"HFFFFH\",\n",
    "    \"HFHHFH\",\n",
    "    \"HFHHFH\",\n",
    "    \"HFFFFF\",\n",
    "    \"HHHHHG\",\n",
    "] \n",
    "\n",
    "env6 = gym.make(\"FrozenLake-v1\",desc=m_66_6,map_name=\"6x6\",is_slippery=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making gym environment (8x8 environment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "m_88 =[\n",
    "    \"SFFFFFFF\",\n",
    "    \"FFFFFFFF\",\n",
    "    \"FFFFFFFF\",\n",
    "    \"FFFFFHFF\",\n",
    "    \"FFFHFFFF\",\n",
    "    \"FHHFFFHF\",\n",
    "    \"FHFFHFHF\",\n",
    "    \"FFFHFFFG\",\n",
    "] \n",
    "\n",
    "env = gym.make(\"FrozenLake-v1\",desc=m_88,map_name=\"8x8\",render_mode=\"human\",is_slippery=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making gym environment (16x16 environment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "m_88 =[\n",
    "    \"SFFFFFFFFF\",\n",
    "    \"FFFFFFFFFF\",\n",
    "    \"FFFFFFFFFF\",\n",
    "    \"FFFFFHFFFF\",\n",
    "    \"FFFHFFFFFF\",\n",
    "    \"FHHFFFHFFF\",\n",
    "    \"FHFFHFHFFF\",\n",
    "    \"FFFHFFFGFF\",\n",
    "] \n",
    "# in case you need rendering\n",
    "# env = gym.make(\"FrozenLake-v1\",desc=m_88,map_name=\"10x10\",render_mode=\"human\",is_slippery=False)\n",
    "# omitting the rendering part\n",
    "env = gym.make(\"FrozenLake-v1\",desc=m_88,map_name=\"10x10\",is_slippery=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rendering environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close Environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m env\u001b[39m.\u001b[39mclose()\n\u001b[0;32m      2\u001b[0m env1\u001b[39m.\u001b[39mclose()\n\u001b[1;32m----> 3\u001b[0m env2\u001b[39m.\u001b[39mclose()\n\u001b[0;32m      4\u001b[0m env3\u001b[39m.\u001b[39mclose()\n\u001b[0;32m      5\u001b[0m env4\u001b[39m.\u001b[39mclose()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'env2' is not defined"
     ]
    }
   ],
   "source": [
    "env.close()\n",
    "env1.close()\n",
    "env2.close()\n",
    "env3.close()\n",
    "env4.close()\n",
    "env5.close()\n",
    "env6.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space:  Discrete(4)\n",
      "Observation space:  Discrete(64)\n"
     ]
    }
   ],
   "source": [
    "# frozen-lake-ex1.py\n",
    "print(\"Action space: \", env.action_space)\n",
    "print(\"Observation space: \", env.observation_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gym environment output check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.0 False False {'prob': 1.0}\n",
      "1 0.0 False False {'prob': 1.0}\n",
      "0 0.0 False False {'prob': 1.0}\n",
      "4 0.0 False False {'prob': 1.0}\n",
      "4 0.0 False False {'prob': 1.0}\n",
      "0 0.0 False False {'prob': 1.0}\n",
      "0 0.0 False False {'prob': 1.0}\n",
      "1 0.0 False False {'prob': 1.0}\n",
      "5 0.0 True False {'prob': 1.0}\n"
     ]
    }
   ],
   "source": [
    "MAX_ITERATIONS = 10\n",
    "env.reset()\n",
    "#env.render()\n",
    "for i in range(MAX_ITERATIONS):\n",
    "    random_action = env.action_space.sample()\n",
    "    new_state, reward, done, info, dep= env.step(random_action)\n",
    "    print(new_state, reward, done, info, dep)\n",
    "    #env.render()\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting action space env size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space\n",
    "env.nS = env.observation_space.n\n",
    "env.nA = env.action_space.n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(1.0, 0, 0.0, False)],\n",
       " 1: [(1.0, 10, 0.0, False)],\n",
       " 2: [(1.0, 1, 0.0, False)],\n",
       " 3: [(1.0, 0, 0.0, False)]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.P[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value iteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def value_iteration(env, max_iterations=100000, lmbda=0.9):\n",
    "  env.nS = env.observation_space.n\n",
    "  env.nA = env.action_space.n \n",
    "  stateValue = [0 for i in range(env.nS)]\n",
    "  newStateValue = stateValue.copy()\n",
    "  for i in range(max_iterations):\n",
    "    for state in range(env.nS):\n",
    "      action_values = []      \n",
    "      for action in range(env.nA):\n",
    "        state_value = 0\n",
    "        for i in range(len(env.P[state][action])):\n",
    "          new_var = env.P[state][action][i]\n",
    "          prob, next_state, reward, done = new_var\n",
    "          state_action_value = prob * (reward + lmbda*stateValue[next_state])\n",
    "          state_value += state_action_value\n",
    "        action_values.append(state_value)      #the value of each action\n",
    "        best_action = np.argmax(np.asarray(action_values))   # choose the action which gives the maximum value\n",
    "        newStateValue[state] = action_values[best_action]  #update the value of the state\n",
    "    if i > 1000: \n",
    "      if sum(stateValue) - sum(newStateValue) < 1e-04:   # if there is negligible difference break the loop\n",
    "        break\n",
    "        print(i)\n",
    "    else:\n",
    "      stateValue = newStateValue.copy()\n",
    "  print(i)\n",
    "  return stateValue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "statevalue = value_iteration(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.7290000000000001,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.81,\n",
       " 0.9,\n",
       " 1.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#env.action_space.n\n",
    "statevalue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting policy for Value iteration algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_policy(env,stateValue, lmbda=0.9):\n",
    "  policy = [0 for i in range(env.nS)]\n",
    "  for state in range(env.nS):\n",
    "    action_values = []\n",
    "    for action in range(env.nA):\n",
    "      action_value = 0\n",
    "      for i in range(len(env.P[state][action])):\n",
    "        prob, next_state, r, _ = env.P[state][action][i]\n",
    "        action_value += prob * (r + lmbda * stateValue[next_state])\n",
    "      action_values.append(action_value)\n",
    "    best_action = np.argmax(np.asarray(action_values))\n",
    "    policy[state] = best_action\n",
    "  return policy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2, 2, 2, 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = get_policy(env, statevalue)\n",
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.7290000000000001,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.81,\n",
       " 0.9,\n",
       " 1.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy\n",
    "#policy[1]\n",
    "#x_1,x_2,x_3,x_4,x_5 =env.step(1)\n",
    "#print(x_1,x_2,x_3,x_4,x_5)\n",
    "#policy\n",
    "#observation = env.reset\n",
    "#policy[:]\n",
    "statevalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(env, policy, episodes=10):\n",
    "  misses = 0\n",
    "  steps_list = []\n",
    "  for episode in range(episodes):\n",
    "    observations = env.reset()\n",
    "    observation = observations[0]\n",
    "    steps=0\n",
    "    while True:\n",
    "      \n",
    "      action = policy[observation]\n",
    "      observation, reward, done, trunc, info = env.step(action)\n",
    "      steps+=1\n",
    "      if done and reward == 1:\n",
    "        # print('You have got the fucking Frisbee after {} steps'.format(steps))\n",
    "        steps_list.append(steps)\n",
    "        break\n",
    "      elif done and reward == 0:\n",
    "        # print(\"You fell in a hole!\")\n",
    "        misses += 1\n",
    "        break\n",
    "  print('----------------------------------------------')\n",
    "  print('You took an average of {:.0f} steps to get the frisbee'.format(np.mean(steps_list)))\n",
    "  print('And you fell in the hole {:.2f} % of the times'.format((misses/episodes) * 100))\n",
    "  print('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m get_score(env, policy)\n",
      "Cell \u001b[1;32mIn [11], line 11\u001b[0m, in \u001b[0;36mget_score\u001b[1;34m(env, policy, episodes)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m   action \u001b[39m=\u001b[39m policy[observation]\n\u001b[1;32m---> 11\u001b[0m   observation, reward, done, trunc, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     12\u001b[0m   steps\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     13\u001b[0m   \u001b[39mif\u001b[39;00m done \u001b[39mand\u001b[39;00m reward \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m     14\u001b[0m     \u001b[39m# print('You have got the fucking Frisbee after {} steps'.format(steps))\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\amirh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gym\\wrappers\\time_limit.py:50\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m     40\u001b[0m     \u001b[39m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32mc:\\Users\\amirh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gym\\wrappers\\order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[0;32m     36\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling env.reset()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\amirh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gym\\wrappers\\env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m env_step_passive_checker(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv, action)\n\u001b[0;32m     38\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\amirh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gym\\envs\\toy_text\\frozen_lake.py:252\u001b[0m, in \u001b[0;36mFrozenLakeEnv.step\u001b[1;34m(self, a)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlastaction \u001b[39m=\u001b[39m a\n\u001b[0;32m    251\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 252\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrender()\n\u001b[0;32m    253\u001b[0m \u001b[39mreturn\u001b[39;00m (\u001b[39mint\u001b[39m(s), r, t, \u001b[39mFalse\u001b[39;00m, {\u001b[39m\"\u001b[39m\u001b[39mprob\u001b[39m\u001b[39m\"\u001b[39m: p})\n",
      "File \u001b[1;32mc:\\Users\\amirh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gym\\envs\\toy_text\\frozen_lake.py:279\u001b[0m, in \u001b[0;36mFrozenLakeEnv.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_render_text()\n\u001b[0;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# self.render_mode in {\"human\", \"rgb_array\"}:\u001b[39;00m\n\u001b[1;32m--> 279\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_render_gui(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrender_mode)\n",
      "File \u001b[1;32mc:\\Users\\amirh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gym\\envs\\toy_text\\frozen_lake.py:373\u001b[0m, in \u001b[0;36mFrozenLakeEnv._render_gui\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    371\u001b[0m     pygame\u001b[39m.\u001b[39mevent\u001b[39m.\u001b[39mpump()\n\u001b[0;32m    372\u001b[0m     pygame\u001b[39m.\u001b[39mdisplay\u001b[39m.\u001b[39mupdate()\n\u001b[1;32m--> 373\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclock\u001b[39m.\u001b[39;49mtick(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetadata[\u001b[39m\"\u001b[39;49m\u001b[39mrender_fps\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m    374\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrgb_array\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    375\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mtranspose(\n\u001b[0;32m    376\u001b[0m         np\u001b[39m.\u001b[39marray(pygame\u001b[39m.\u001b[39msurfarray\u001b[39m.\u001b[39mpixels3d(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_surface)), axes\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "get_score(env, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "def qlearning(env,total_episodes):\n",
    "    action_size = env.action_space.n\n",
    "    state_size = env.observation_space.n\n",
    "    qtable = np.zeros((state_size, action_size))\n",
    "    #total_episodes = 100000        # Total episodes\n",
    "    learning_rate = 0.9           # Learning rate\n",
    "    max_steps = 99                # Max steps per episode\n",
    "    gamma = 0.95                  # Discounting rate\n",
    "\n",
    "    # Exploration parameters\n",
    "    epsilon = 1                # Exploration rate\n",
    "    max_epsilon = 1.0             # Exploration probability at start\n",
    "    min_epsilon = 0.01            # Minimum exploration probability \n",
    "    decay_rate = 1/total_episodes             # Exponential decay rate for exploration prob\n",
    "    # List of rewards\n",
    "    rewards = []\n",
    "    # 2 For life or until learning is stopped\n",
    "    for episode in range(total_episodes):\n",
    "        # Reset the environment\n",
    "        state_reset = env.reset()\n",
    "        state = state_reset[0]\n",
    "        #print(state)\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            # 3. Choose an action a in the current world state (s)\n",
    "            ## First we randomize a number\n",
    "            exp_exp_tradeoff = random.uniform(0, 1)\n",
    "            #print(exp_exp_tradeoff)\n",
    "            ## If this number > greater than epsilon --> exploitation (taking the biggest Q value for this state)\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                action = np.argmax(qtable[state,:])\n",
    "\n",
    "            # Else doing a random choice --> exploration\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "                #print(action)\n",
    "\n",
    "            # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "            new_state, reward, done, trunc, info = env.step(action)\n",
    "\n",
    "            # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "            # qtable[new_state,:] : all the actions we can take from new state\n",
    "            #print(state,action,reward)\n",
    "            qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * np.max(qtable[new_state, :]) - qtable[state, action])\n",
    "            \n",
    "            total_rewards += reward\n",
    "            \n",
    "            # Our new state is state\n",
    "            state = new_state\n",
    "            \n",
    "            # If done (if we're dead) : finish episode\n",
    "            if done == True: \n",
    "                break\n",
    "            \n",
    "        episode += 1\n",
    "        # Reduce epsilon (because we need less and less exploration)\n",
    "        \n",
    "        #epsilon = epsilon*decay\n",
    "        #epsilon = epsilon*0.999999\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode) \n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "    #print (\"Score over time: \" +  str(sum(rewards)/total_episodes))\n",
    "    #print(episode)\n",
    "    return(qtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Exploration parameters\n",
    "epsilon = 1                # Exploration rate\n",
    "max_epsilon = 1.0             # Exploration probability at start\n",
    "min_epsilon = 0.01            # Minimum exploration probability \n",
    "           # Exponential decay rate for exploration pro\n",
    "ep = 0\n",
    "data_collection_rate = 100\n",
    "d = 1\n",
    "epfun1 = epsilon\n",
    "epfun2 = epsilon\n",
    "epfun1list = []\n",
    "epfun2list = []\n",
    "total_ep = 10000\n",
    "decay_rate = 1/total_ep\n",
    "while ep<total_ep:\n",
    "    ep = ep + 1\n",
    "    epfun1 = epfun1*0.9999\n",
    "    epfun2 = epfun2 = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*ep)\n",
    "    if ep == ((total_ep)/(data_collection_rate))*d:\n",
    "        epfun1list.append(epfun1)\n",
    "        epfun2list.append(epfun2)\n",
    "        d = d + 1\n",
    "#print(epfun1list)\n",
    "epfun1array = np.array(epfun1list)\n",
    "epfun2array = np.array(epfun2list)\n",
    "ep_array = np.array(list(range(0,data_collection_rate)))\n",
    "#print(epfun1array)\n",
    "#print(ep_array)\n",
    "\n",
    "plt.scatter(ep_array,epfun1array,c='y',edgecolor =\"blue\",linewidths=0.1,marker='D',s=4,alpha=0.5)\n",
    "plt.scatter(ep_array,epfun2array,c='b',edgecolor =\"red\",linewidths=0.1,marker='p',s=4, alpha=0.5)\n",
    "\n",
    "plt.title('Epsilon greedy decay rate')\n",
    "plt.xlabel('Elapsed episode pecentage')\n",
    "plt.ylabel('Epsilon Value')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.59873694 0.         0.63024941 0.59873694]\n",
      " [0.59873694 0.66342043 0.66342043 0.63024941]\n",
      " [0.63024941 0.6983373  0.6983373  0.66342043]\n",
      " [0.66342043 0.73509189 0.73509189 0.6983373 ]\n",
      " [0.6983373  0.77378094 0.6983373  0.73509189]\n",
      " [0.73509189 0.         0.6983373  0.6983373 ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.6983373  0.6983373  0.63024941]\n",
      " [0.66342043 0.         0.73509189 0.66342043]\n",
      " [0.6983373  0.         0.77378094 0.6983373 ]\n",
      " [0.73509189 0.81450625 0.         0.73509189]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.73509189 0.         0.66342043]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.857375   0.         0.77378094]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.77378094 0.         0.6983373 ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.9025     0.         0.81450625]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.81450625 0.73509189]\n",
      " [0.77378094 0.         0.857375   0.        ]\n",
      " [0.81450625 0.         0.9025     0.        ]\n",
      " [0.857375   0.         0.95       0.857375  ]\n",
      " [0.9025     1.         0.95       0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "qtable = qlearning (env6,50000)\n",
    "print(qtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score over time: 0.01325\n",
      "100000\n",
      "***The mesh is ok***\n",
      "*** so meshing parameter is 1 ***\n"
     ]
    }
   ],
   "source": [
    "qtable = qlearning(env)\n",
    "meshing = 1\n",
    "if np.argmax(qtable) == 0:\n",
    "    meshing = 0\n",
    "    print('***The mesh must be more dense***')\n",
    "else:\n",
    "    print('***The mesh is ok***')\n",
    "print('*** so meshing parameter is',meshing,'***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mesh must be larger\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "meshing = 0\n",
    "if np.argmax(qtable) == 0:\n",
    "    meshing = 1\n",
    "    print('The mesh must be larger')\n",
    "print(meshing) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-learning implementation and rendering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_moving_check(env,qtable, number_of_episodes):\n",
    "\n",
    "    env.reset()\n",
    "    max_steps = 16\n",
    "    for episode in range(number_of_episodes):\n",
    "        state = env.reset()\n",
    "        state = state[0]\n",
    "        step = 0\n",
    "        done = False\n",
    "        #print(\"****************************************************\")\n",
    "        #print(\"EPISODE \", episode)\n",
    "        #print(state)\n",
    "        for step in range(max_steps):\n",
    "            # env.render()\n",
    "            # Take the action (index) that have the maximum expected future reward given that state\n",
    "            action = np.argmax(qtable[state,:])\n",
    "            #print(action)\n",
    "            new_state, reward, done, trunc, info = env.step(action)\n",
    "            if done:\n",
    "                if reward == 1:\n",
    "                    return(reward)\n",
    "                else:\n",
    "                    reward = 0\n",
    "                    return(reward)\n",
    "                #print('epis length',step)\n",
    "                #print('reward',reward)\n",
    "                break\n",
    "            if step == max_steps:\n",
    "                reward = 0\n",
    "                return(reward) \n",
    "\n",
    "            state = new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_moving_check(env6,qtable,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def q_performance(env,max_ep,data_collect,points_distance_accordingtodatacollect):\n",
    "    ep = 0\n",
    "    #success_list = np.array(list(range(0,data_collect)))\n",
    "    success_list = np.array([])\n",
    "    while ep<max_ep:\n",
    "        rewards = 0 # total rewards per data collection section\n",
    "        success_rate = 0 # success rate in each data sampling session \n",
    "        ep_it = int(data_collect/points_distance_accordingtodatacollect) # number of test points in each data collection session\n",
    "        for s in range(ep_it): \n",
    "            ep = ep + points_distance_accordingtodatacollect # iteration through max episodes\n",
    "            qtable = qlearning (env,ep)\n",
    "            reward = Q_moving_check(env,qtable,1) or 0\n",
    "            rewards +=  reward\n",
    "        success_rate = rewards/ep_it\n",
    "        success_list = np.append(success_list, success_rate) # you have to make a list which each element is average eward per data collect\n",
    "        #return success_list\n",
    "    return success_list\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance test for one 4x4 map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "data_collect = 500 # data collection rate\n",
    "max_ep = 5000 # max episode for performance check\n",
    "points_distance_accordingtodatacollect = 10 # how many points calculated in data collect session to reduce calculation costs \n",
    "# final average is based on this number\n",
    "\n",
    "\n",
    "## performance check based on elapsed episodes (training)\n",
    "\n",
    "success_list = q_performance(env5,max_ep,data_collect,points_distance_accordingtodatacollect)\n",
    "success_list_1 = q_performance(env6,max_ep,data_collect,points_distance_accordingtodatacollect)\n",
    "\n",
    "## ploting the data\n",
    "\n",
    "data_points = max_ep/data_collect\n",
    "data_points_array = np.array(list(range(0,int(data_points))))\n",
    "\n",
    "print(data_points_array,success_list)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.scatter(data_points_array,success_list,c='b',edgecolor =\"red\",linewidths=0.5,marker='p',s=10, alpha=0.7,label='Env1')\n",
    "plt.scatter(data_points_array,success_list_1,c='r',edgecolor =\"red\",linewidths=0.5,marker='p',s=10, alpha=0.7,label='Env2')\n",
    "\n",
    "plt.title('Performance check for')\n",
    "plt.xlabel('Elapsed episode pecentage')\n",
    "plt.ylabel('Performance per data collect rate')\n",
    "\n",
    "leg = ax.legend(scatterpoints=1, frameon=True, labelspacing=1, title='Different maps')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance test for 6 maps 6x6 map with close comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env1 done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [23], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m success_list_1 \u001b[39m=\u001b[39m q_performance(env1,max_ep,data_collect)\n\u001b[0;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEnv1 done\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m success_list_2 \u001b[39m=\u001b[39m q_performance(env2,max_ep,data_collect)\n\u001b[0;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEnv2 done\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m success_list_3 \u001b[39m=\u001b[39m q_performance(env3,max_ep,data_collect)\n",
      "Cell \u001b[1;32mIn [12], line 11\u001b[0m, in \u001b[0;36mq_performance\u001b[1;34m(env, max_ep, data_collect)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(data_collect): \n\u001b[0;32m     10\u001b[0m     ep \u001b[39m=\u001b[39m ep \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m# iteration through max episodes\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     qtable \u001b[39m=\u001b[39m qlearning (env,ep)\n\u001b[0;32m     12\u001b[0m     reward \u001b[39m=\u001b[39m Q_moving_check(env,qtable,\u001b[39m1\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m     13\u001b[0m     rewards \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m  reward\n",
      "Cell \u001b[1;32mIn [2], line 37\u001b[0m, in \u001b[0;36mqlearning\u001b[1;34m(env, total_episodes)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39m#print(exp_exp_tradeoff)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39m## If this number > greater than epsilon --> exploitation (taking the biggest Q value for this state)\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39mif\u001b[39;00m exp_exp_tradeoff \u001b[39m>\u001b[39m epsilon:\n\u001b[1;32m---> 37\u001b[0m     action \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49margmax(qtable[state,:])\n\u001b[0;32m     39\u001b[0m \u001b[39m# Else doing a random choice --> exploration\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     action \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39msample()\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\amirh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1216\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m \u001b[39mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1213\u001b[0m \u001b[39m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m kwds \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mkeepdims\u001b[39m\u001b[39m'\u001b[39m: keepdims} \u001b[39mif\u001b[39;00m keepdims \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39m_NoValue \u001b[39melse\u001b[39;00m {}\n\u001b[1;32m-> 1216\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39m\u001b[39margmax\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\amirh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "data_collect = 100 # data collection rate\n",
    "max_ep = 5000 # max episode for performance check\n",
    "\n",
    "## performance check based on elapsed episodes (training)\n",
    "\n",
    "success_list_1 = q_performance(env1,max_ep,data_collect)\n",
    "print('Env1 done')\n",
    "success_list_2 = q_performance(env2,max_ep,data_collect)\n",
    "print('Env2 done')\n",
    "success_list_3 = q_performance(env3,max_ep,data_collect)\n",
    "print('Env3 done')\n",
    "success_list_4 = q_performance(env4,max_ep,data_collect)\n",
    "print('Env4 done')\n",
    "success_list_5 = q_performance(env5,max_ep,data_collect)\n",
    "print('Env5 done')\n",
    "success_list_6 = q_performance(env6,max_ep,data_collect)\n",
    "print('Env6 done')\n",
    "\n",
    "## ploting the data\n",
    "\n",
    "data_points = max_ep/data_collect\n",
    "data_points_array = np.array(list(range(0,int(data_points))))\n",
    "\n",
    "print(data_points_array,success_list)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.scatter(data_points_array,success_list_1,c='C1',edgecolor =\"red\",linewidths=0.1,marker='o',s=10, alpha=0.5,label='Env1')\n",
    "plt.scatter(data_points_array,success_list_2,c='C2',edgecolor =\"red\",linewidths=0.1,marker='s',s=10, alpha=0.5,label='Env2')\n",
    "plt.scatter(data_points_array,success_list_3,c='C3',edgecolor =\"red\",linewidths=0.1,marker='X',s=10, alpha=0.5,label='Env3')\n",
    "plt.scatter(data_points_array,success_list_4,c='C4',edgecolor =\"red\",linewidths=0.1,marker='D',s=10, alpha=0.5,label='Env4')\n",
    "plt.scatter(data_points_array,success_list_5,c='C5',edgecolor =\"red\",linewidths=0.1,marker='p',s=10, alpha=0.5,label='Env5')\n",
    "plt.scatter(data_points_array,success_list_6,c='C6',edgecolor =\"red\",linewidths=0.1,marker='*',s=10, alpha=0.5,label='Env6')\n",
    "\n",
    "plt.title('Performance check for')\n",
    "plt.xlabel('Elapsed episode pecentage')\n",
    "plt.ylabel('Performance per data collect rate')\n",
    "\n",
    "leg = ax.legend(scatterpoints=1, frameon=True, labelspacing=1, title='Different maps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49] []\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [88], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m data_points_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39mint\u001b[39m(data_points))))\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(data_points_array,success_list)\n\u001b[1;32m----> 8\u001b[0m plt\u001b[39m.\u001b[39;49mscatter(data_points_array,success_list,c\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mb\u001b[39;49m\u001b[39m'\u001b[39;49m,edgecolor \u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mred\u001b[39;49m\u001b[39m\"\u001b[39;49m,linewidths\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m,marker\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mp\u001b[39;49m\u001b[39m'\u001b[39;49m,s\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, alpha\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m)\n\u001b[0;32m     10\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mPerformance check for\u001b[39m\u001b[39m'\u001b[39m,max_ep,\u001b[39m'\u001b[39m\u001b[39mData collection rate\u001b[39m\u001b[39m'\u001b[39m,data_collect)\n\u001b[0;32m     11\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mElapsed episode pecentage\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\amirh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\pyplot.py:2790\u001b[0m, in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[0;32m   2785\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mscatter)\n\u001b[0;32m   2786\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscatter\u001b[39m(\n\u001b[0;32m   2787\u001b[0m         x, y, s\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, c\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, marker\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, cmap\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, norm\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2788\u001b[0m         vmin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, vmax\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, alpha\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, linewidths\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m,\n\u001b[0;32m   2789\u001b[0m         edgecolors\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, plotnonfinite\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2790\u001b[0m     __ret \u001b[39m=\u001b[39m gca()\u001b[39m.\u001b[39mscatter(\n\u001b[0;32m   2791\u001b[0m         x, y, s\u001b[39m=\u001b[39ms, c\u001b[39m=\u001b[39mc, marker\u001b[39m=\u001b[39mmarker, cmap\u001b[39m=\u001b[39mcmap, norm\u001b[39m=\u001b[39mnorm,\n\u001b[0;32m   2792\u001b[0m         vmin\u001b[39m=\u001b[39mvmin, vmax\u001b[39m=\u001b[39mvmax, alpha\u001b[39m=\u001b[39malpha, linewidths\u001b[39m=\u001b[39mlinewidths,\n\u001b[0;32m   2793\u001b[0m         edgecolors\u001b[39m=\u001b[39medgecolors, plotnonfinite\u001b[39m=\u001b[39mplotnonfinite,\n\u001b[0;32m   2794\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m({\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m: data} \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2795\u001b[0m     sci(__ret)\n\u001b[0;32m   2796\u001b[0m     \u001b[39mreturn\u001b[39;00m __ret\n",
      "File \u001b[1;32mc:\\Users\\amirh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\__init__.py:1423\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m   1421\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1422\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1423\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(sanitize_sequence, args), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1425\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1426\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[0;32m   1427\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mc:\\Users\\amirh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\axes\\_axes.py:4520\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4518\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mravel(y)\n\u001b[0;32m   4519\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39msize \u001b[39m!=\u001b[39m y\u001b[39m.\u001b[39msize:\n\u001b[1;32m-> 4520\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mx and y must be the same size\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   4522\u001b[0m \u001b[39mif\u001b[39;00m s \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4523\u001b[0m     s \u001b[39m=\u001b[39m (\u001b[39m20\u001b[39m \u001b[39mif\u001b[39;00m mpl\u001b[39m.\u001b[39mrcParams[\u001b[39m'\u001b[39m\u001b[39m_internal.classic_mode\u001b[39m\u001b[39m'\u001b[39m] \u001b[39melse\u001b[39;00m\n\u001b[0;32m   4524\u001b[0m          mpl\u001b[39m.\u001b[39mrcParams[\u001b[39m'\u001b[39m\u001b[39mlines.markersize\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2.0\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "data_points = max_ep/data_collect\n",
    "data_points_array = np.array(list(range(0,int(data_points))))\n",
    "print(data_points_array,success_list)\n",
    "plt.scatter(data_points_array,success_list,c='b',edgecolor =\"red\",linewidths=0.1,marker='p',s=4, alpha=0.5)\n",
    "\n",
    "plt.title('Performance check for',max_ep,'Data collection rate',data_collect)\n",
    "plt.xlabel('Elapsed episode pecentage')\n",
    "plt.ylabel('Performance per data collect rate')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_policy(env,qtable,ep):\n",
    "    env.reset()\n",
    "\n",
    "    for episode in range(ep):\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        print(\"****************************************************\")\n",
    "        print(\"EPISODE \", episode)\n",
    "\n",
    "        for step in range(ep):\n",
    "            #env.render()\n",
    "            # Take the action (index) that have the maximum expected future reward given that state\n",
    "            action = np.argmax(qtable[state,:])\n",
    "            \n",
    "            new_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "            state = new_state\n",
    "    #env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************\n",
      "EPISODE  0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Q_policy(env,qtable,ep \u001b[39m=\u001b[39;49m \u001b[39m1000\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn [14], line 14\u001b[0m, in \u001b[0;36mQ_policy\u001b[1;34m(env, qtable, ep)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEPISODE \u001b[39m\u001b[39m\"\u001b[39m, episode)\n\u001b[0;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(ep):\n\u001b[0;32m     12\u001b[0m     \u001b[39m#env.render()\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[39m# Take the action (index) that have the maximum expected future reward given that state\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     action \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(qtable[state,:])\n\u001b[0;32m     16\u001b[0m     new_state, reward, done, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n\u001b[0;32m     18\u001b[0m     \u001b[39mif\u001b[39;00m done:\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "Q_policy(env,qtable,ep = 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89e266229da60c573547888e6703b56490856979bb7179bff867b5e39a966f35"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
